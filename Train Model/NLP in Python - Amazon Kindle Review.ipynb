{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline](pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Familiar with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv file into DataFrame\n",
    "kindle_data = pd.read_csv('sampled_data.csv')\n",
    "type(kindle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall    : pos\n",
      "reviewText : This book ended even before it started and it made me want for more. Oh oh such a teaser. I want the book now please. So exciting.\n"
     ]
    }
   ],
   "source": [
    "# Print first row\n",
    "# Format: data_frame.col_nam[row]\n",
    "print(\"overall    :\", kindle_data.overall[0])\n",
    "print(\"reviewText :\", kindle_data.reviewText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126871"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of kindle_data\n",
    "len(kindle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>This book ended even before it started and it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>This is a great read with so much emotion you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>It&amp;#8217;s Christmas Eve and miraculously, Sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>I enjoyed meeting the character of Cassandra. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Can I be the next Hunter wife?  Again, I have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  overall                                         reviewText\n",
       "0     pos  This book ended even before it started and it ...\n",
       "1     pos  This is a great read with so much emotion you ...\n",
       "2     pos  It&#8217;s Christmas Eve and miraculously, Sal...\n",
       "3     pos  I enjoyed meeting the character of Cassandra. ...\n",
       "4     pos  Can I be the next Hunter wife?  Again, I have ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample (head) of the data frame\n",
    "kindle_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Try `HTMLParser` to un-escape the text as a stage of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It’s Christmas Eve and miraculously, Sally Moss has got her twins tucked up in bed, presents all wra'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "html.unescape(kindle_data.reviewText[2])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    64559\n",
       "neg    62312\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statics on tags\n",
    "kindle_data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split complete data set into [pos, neg]\n",
    "def splitPosNeg(data_):\n",
    "    neg = data_.loc[data_.overall=='neg']\n",
    "    pos = data_.loc[data_.overall=='pos']\n",
    "    return [pos,neg]\n",
    "\n",
    "[pos,neg] = splitPosNeg(kindle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "pos: 64559 , neg: 62312\n"
     ]
    }
   ],
   "source": [
    "print(type(pos))\n",
    "print(\"pos:\", len(pos), \", neg:\", len(neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ywu58/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "translation = str.maketrans(string.punctuation,' '*len(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dedef'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test. Translate abc into def\n",
    "transtbl = str.maketrans('abc','def')\n",
    "'ababc'.translate(transtbl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    tokens=[]\n",
    "    line = str(line).translate(translation)  # Replace punctuation\n",
    "    line = nltk.word_tokenize(line.lower())  # Tokenize\n",
    "    \n",
    "    for t in line:\n",
    "        # Remove stopwords\n",
    "        if t not in stop:\n",
    "            stemmed = lemmatizer.lemmatize(t)\n",
    "            tokens.append(stemmed)\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yet a more compact way to write the code\n",
    "def preprocessing(line: str) -> str:\n",
    "    line = str(line).translate(translation)\n",
    "    line = nltk.word_tokenize(line.lower())\n",
    "    \n",
    "    line = [lemmatizer.lemmatize(t, pos = 'v') for t in line if t not in stop]\n",
    "    line = [lemmatizer.lemmatize(t, pos = 'n') for t in line if t not in stop]\n",
    "    return ' '.join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy yesterday really love apple'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = \"I bought it yesterday and I really love apples!\"\n",
    "preprocessing(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess all data\n",
    "pos_data = [preprocessing(p) for p in pos['reviewText']]\n",
    "neg_data = [preprocessing(p) for p in neg['reviewText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yet a more modern way to write code\n",
    "pos_data = list(map(preprocessing, pos['reviewText']))\n",
    "neg_data = list(map(preprocessing, neg['reviewText']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some modern functions to introduce\n",
    "- map\n",
    "- reduce\n",
    "- filter\n",
    "\n",
    "They are very useful when running the project on a cluster or distributed compute system like Hadoop or Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# Some useful modern functions\n",
    "l = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "# Map\n",
    "def square(x: int) -> int:\n",
    "    return x * x\n",
    "\n",
    "print( list(map(square, l)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# Using lambda function\n",
    "\n",
    "print( list(map(lambda x: x * x, l)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x * x for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] by add: 45\n"
     ]
    }
   ],
   "source": [
    "# Reduce\n",
    "# reduce function is moved to functools\n",
    "def add(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "rst = functools.reduce(add, l)\n",
    "print (\"reduce\", l, \"by add:\", rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] by add: 45\n"
     ]
    }
   ],
   "source": [
    "# Using lambda function\n",
    "# reduce is moved to functools in Python 3\n",
    "rst = functools.reduce(lambda x, y: x + y, l)\n",
    "print (\"reduce\", l, \"by add:\", rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] by min: 0\n"
     ]
    }
   ],
   "source": [
    "rst = functools.reduce(lambda x, y: min(x, y), l)\n",
    "print (\"reduce\", l, \"by min:\", rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter\n",
    "# Much faster than loop, similar with list comprehension\n",
    "list(filter(lambda x: x < 5, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Data & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>This book ended even before it started and it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>This is a great read with so much emotion you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>It&amp;#8217;s Christmas Eve and miraculously, Sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>I enjoyed meeting the character of Cassandra. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Can I be the next Hunter wife?  Again, I have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  overall                                         reviewText\n",
       "0     pos  This book ended even before it started and it ...\n",
       "1     pos  This is a great read with so much emotion you ...\n",
       "2     pos  It&#8217;s Christmas Eve and miraculously, Sal...\n",
       "3     pos  I enjoyed meeting the character of Cassandra. ...\n",
       "4     pos  Can I be the next Hunter wife?  Again, I have ..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pos_data + neg_data\n",
    "labels = np.concatenate((pos['overall'].values,neg['overall'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'pos', ..., 'neg', 'neg', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training set and testing set (20:80)\n",
    "# stratify: make sure pos/neg remains the same in training set and testing set\n",
    "train_data, test_data, train_labels, test_labels = \\\n",
    "train_test_split(\n",
    "    data, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    stratify=labels, \n",
    "    random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size =  101496 testing size =  25375\n"
     ]
    }
   ],
   "source": [
    "print(\"training size = \", len(train_data), \"testing size = \", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfitting vs Overfitting\n",
    "![](http://scikit-learn.org/stable/_images/sphx_glr_plot_underfitting_overfitting_001.png)\n",
    "\n",
    "Common Method:\n",
    "- 20:80 Split\n",
    "- K-fold\n",
    "\n",
    "To estimate accuracy (f-score):\n",
    "- 20:20:60 Split\n",
    "- 10:20:70 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Push all tokens and compute frequency of words\n",
    "t = []\n",
    "for line in train_data:\n",
    "    l = nltk.word_tokenize(line)\n",
    "    for w in l:\n",
    "        t.append(w)\n",
    "        \n",
    "word_features = nltk.FreqDist(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yet another more python-y style\n",
    "tokens = [word for line in train_data \\\n",
    "               for word in nltk.word_tokenize(line)]\n",
    "\n",
    "word_features = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 76266 samples and 4188749 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('book', 124119),\n",
       " ('read', 74580),\n",
       " ('story', 62132),\n",
       " ('like', 39143),\n",
       " ('one', 36880),\n",
       " ('love', 35376),\n",
       " ('get', 33777),\n",
       " ('character', 30268),\n",
       " ('good', 28930),\n",
       " ('would', 27660)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topwords = [fpair[0] for fpair in list(word_features.most_common(10000))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vec = CountVectorizer()\n",
    "cnt_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x9968 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9968 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our BAG of words (specify words we care about)\n",
    "cnt_fit = cnt_vec.fit_transform([' '.join(topwords)])\n",
    "cnt_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf–idf term weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tf: term-frequency\n",
    "- idf: inverse document-frequency\n",
    "- Tf-idf = $tf(t,d) \\times idf(t)$\n",
    "\n",
    "$$\n",
    "idf(t) = log{\\frac{1 + nd}{1 + df(d, t)}} + 1\n",
    "$$\n",
    "\n",
    "![](http://www.onemathematicalcat.org/Math/Algebra_II_obj/Graphics/log_base_gt1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sentent 1: The boy **love** the toy\n",
    "\n",
    "> Sentent 2: The boy **hate** the toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume vocabulary = ['The', 'boy', 'the', 'toy', 'love', 'hate']\n",
    "counts = [[1, 1, 1, 1, 1, 0],\n",
    "          [1, 1, 1, 1, 0, 1]]\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4090901 ,  0.4090901 ,  0.4090901 ,  0.4090901 ,  0.57496187,\n",
       "         0.        ],\n",
       "       [ 0.4090901 ,  0.4090901 ,  0.4090901 ,  0.4090901 ,  0.        ,\n",
       "         0.57496187]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x9968 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9968 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_trans = TfidfTransformer()\n",
    "tf_fit = tf_trans.fit_transform(cnt_fit)\n",
    "tf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x9968 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9968 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since CountVectorizer and TfidTransformer are often used together\n",
    "# There is a class named TfidfVectorizer that combine these two steps\n",
    "tf_vec = TfidfVectorizer()\n",
    "tf_fit = tf_vec.fit_transform([' '.join(topwords)])\n",
    "tf_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features from training set\n",
    "# Vocabulary is from topwords\n",
    "train_features = tf_vec.transform(train_data)\n",
    "\n",
    "# cnt_train_features = cnt_vec.transform(train_data)\n",
    "# train_features = tf_trans.transform(cnt_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101496, 9968)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array[n_train_data * n_features]\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features from test set\n",
    "test_features = tf_vec.transform(test_data)\n",
    "\n",
    "# cnt_test_features = cnt_vec.transform(test_data)\n",
    "# test_features = tf_trans.transform(cnt_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101496, 19935)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Uni+Bi)-Gram\n",
    "bg_tf_vec = TfidfVectorizer(ngram_range=(1,2))\n",
    "bg_tf_vec.fit([' '.join(topwords)])\n",
    "bg_train_features = bg_tf_vec.transform(train_data)\n",
    "\n",
    "bg_train_features.shape\n",
    "\n",
    "# Array[n_train_data * (uni_gram_features + bi_gram_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract (uni+bi)-gram test features\n",
    "bg_test_features = bg_tf_vec.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Multinomial NB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for **classification with discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB model trained in 0.268600 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "start = time.time()\n",
    "mnb_model.fit(train_features, train_labels)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Multinomial NB model trained in %f seconds\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'pos' 'pos' ..., 'neg' 'pos' 'neg']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "pred = mnb_model.predict(test_features)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816945812808\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "# metrics.accuracy_score(y_true, y_pred)\n",
    "accuracy = metrics.accuracy_score(pred,test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.82      0.80      0.81     12463\n",
      "        pos       0.81      0.84      0.82     12912\n",
      "\n",
      "avg / total       0.82      0.82      0.82     25375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use keyword arguments to set arguments explicitly\n",
    "print(metrics.classification_report(y_true=test_labels, y_pred=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.50      1.00      0.67         1\n",
      "    class 1       0.00      0.00      0.00         1\n",
      "    class 2       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example from sklearn documentation\n",
    "\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(metrics.classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & test using Uni-Gram + Bi-Gram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'pos' 'pos' ..., 'neg' 'pos' 'neg']\n"
     ]
    }
   ],
   "source": [
    "# Train & test using (uni+bi)-gram features\n",
    "bg_mnb_model = MultinomialNB()\n",
    "bg_mnb_model.fit(bg_train_features, train_labels)\n",
    "bg_pred = bg_mnb_model.predict(bg_test_features)\n",
    "print(bg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816157635468\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "bg_accuracy = metrics.accuracy_score(bg_pred,test_labels)\n",
    "print(bg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.83      0.79      0.81     12463\n",
      "        pos       0.81      0.84      0.82     12912\n",
      "\n",
      "avg / total       0.82      0.82      0.82     25375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=test_labels, y_pred=bg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other possible models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "SVC model trained in: 1.96s\n",
      "\n",
      "Accuracy = 0.83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.83      0.82      0.82     12463\n",
      "        pos       0.83      0.83      0.83     12912\n",
      "\n",
      "avg / total       0.83      0.83      0.83     25375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_model = LinearSVC()\n",
    "print(svc_model, end='\\n'*2)\n",
    "\n",
    "start = time.time()\n",
    "svc_model.fit(train_features, train_labels)\n",
    "end = time.time()\n",
    "print('SVC model trained in: %.2fs' % (end - start), end='\\n'*2)\n",
    "svc_pred = svc_model.predict(test_features)\n",
    "\n",
    "print('Accuracy = %.2f' % metrics.accuracy_score(svc_pred, test_labels))\n",
    "print(metrics.classification_report(y_pred=svc_pred, y_true=test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "SVC model trained in: 1.87s\n",
      "\n",
      "Accuracy = 0.83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.83      0.82      0.82     12463\n",
      "        pos       0.83      0.83      0.83     12912\n",
      "\n",
      "avg / total       0.83      0.83      0.83     25375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LinearSVC()\n",
    "print(lr_model, end='\\n'*2)\n",
    "\n",
    "start = time.time()\n",
    "lr_model.fit(train_features, train_labels)\n",
    "end = time.time()\n",
    "print('SVC model trained in: %.2fs' % (end - start), end='\\n'*2)\n",
    "lr_pred = lr_model.predict(test_features)\n",
    "\n",
    "print('Accuracy = %.2f' % metrics.accuracy_score(lr_pred, test_labels))\n",
    "print(metrics.classification_report(y_pred=lr_pred, y_true=test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict new sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict a new sentence\n",
    "# vectorizer needs to be pre-fitted\n",
    "# At the end of the project, the function signature should be something like:\n",
    "# predict_new(sentent: str, vec, model) -> str\n",
    "\n",
    "def predict_new(sentence: str):\n",
    "    sentence = preprocessing(sentence)\n",
    "    features = tf_vec.transform([sentence])\n",
    "    pred = mnb_model.predict(features)\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_new(\"not good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save vectorizer\n",
    "with open('tf_vec.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(tf_vec, pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open('mnb_model.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(mnb_model, pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
